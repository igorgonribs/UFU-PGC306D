{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k475s1q5kZA4"
   },
   "source": [
    "##  <font style=\"color:black\">**Curso de Analytics de Imagens e Vídeos**</font>\n",
    "\n",
    "Aula 08 - Classificação de imagens usando RNAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLzXisu_B43r"
   },
   "source": [
    "## **Exemplo prático**\n",
    "\n",
    "Criação e treinamento de rede neural com Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 13676,
     "status": "ok",
     "timestamp": 1756331907871,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "7XjRYFxcVp6V",
    "outputId": "e43c0e9c-76fb-4127-a966-fd5e1638a43d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importação das bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvg8ko9YDUoG"
   },
   "source": [
    "### Funções auxiliares para a execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1756331917385,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "2d3P3-EUDX7C"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy()\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2QKe2hCVzNv"
   },
   "source": [
    "### Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1756331925353,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "F1OqJDIkVv5k"
   },
   "outputs": [],
   "source": [
    "# Especificando o transformador das imagens para o formato específico do pytorch (média = 0.5 e desvio padrão 0.5)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 12220,
     "status": "ok",
     "timestamp": 1756331939700,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "mRda8FOvBqrt"
   },
   "outputs": [],
   "source": [
    "# baixando base de dados de placas de transito\n",
    "import urllib.request\n",
    "import os.path\n",
    "if not os.path.exists(\"GTSRB_Final_Training_Images.zip\"):\n",
    "    url = (\"https://sid.erda.dk/public/archives/\"\n",
    "    + \"daaeac0d7ce1152aea9b61d9f1e19370/\"\n",
    "    + \"GTSRB_Final_Training_Images.zip\")\n",
    "    filename = \"./GTSRB_Final_Training_Images.zip\"\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "IMG_SIZE = 28\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 26976,
     "status": "ok",
     "timestamp": 1756331978560,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "XqUYMQ3SCPRY"
   },
   "outputs": [],
   "source": [
    "# lê o arquivo e separa os datasets de treinamento e teste\n",
    "import zipfile\n",
    "from skimage.transform import resize\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "\n",
    "X, Xt, y, yt = list(), list(), list(), list()\n",
    "\n",
    "archive = zipfile.ZipFile(\n",
    "          'GTSRB_Final_Training_Images.zip', 'r')\n",
    "file_paths = [file for file in archive.namelist()\n",
    "              if '.ppm' in file]\n",
    "\n",
    "for filename in file_paths:\n",
    "    with archive.open(filename) as img_file:\n",
    "        img = Image.open(img_file).convert('L')\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "    img = resize(img,\n",
    "                 output_shape=(IMG_SIZE, IMG_SIZE),\n",
    "                 mode='reflect', anti_aliasing=True)\n",
    "\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    img_class = int(filename.split('/')[-2])\n",
    "\n",
    "    if (hash(filename) % 1000) / 1000 > TEST_SIZE:\n",
    "        X.append(img)\n",
    "        y.append(img_class)\n",
    "    else:\n",
    "        Xt.append(img)\n",
    "        yt.append(img_class)\n",
    "\n",
    "\n",
    "archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_embedded_package_id": "1Y-ec1H1TF7En59EMCfX7-HtA1G1Rd-0o"
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1756331986238,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "e1j2rfjCiyIx",
    "outputId": "9c90b241-0d8d-46ff-a997-d2b354227a5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 77,  76,  87, 101, 125, 128, 142, 169, 237, 248, 238, 203, 149,\n",
       "        145, 176, 215, 239, 232, 200, 151, 100,  97, 106,  93,  79,  73,\n",
       "         68,  67],\n",
       "       [ 83,  81,  91, 119, 140, 106, 131, 205, 251, 250, 229, 170, 151,\n",
       "        172, 182, 205, 231, 240, 229, 178, 117, 101, 105,  98,  84,  76,\n",
       "         76,  79],\n",
       "       [ 77,  85,  95, 133, 122, 111, 195, 246, 252, 246, 216, 179, 205,\n",
       "        222, 178, 177, 216, 236, 243, 209, 145, 119, 111, 103,  90,  74,\n",
       "         72,  77],\n",
       "       [ 74,  85, 103, 134, 112, 137, 213, 241, 249, 238, 210, 193, 218,\n",
       "        232, 222, 195, 196, 216, 215, 212, 172, 113,  93, 116, 110,  76,\n",
       "         73,  79],\n",
       "       [ 73,  92, 119, 129, 111, 145, 194, 213, 204, 194, 174, 165, 173,\n",
       "        172, 160, 151, 144, 138, 125, 126, 113, 100,  89, 100, 118,  82,\n",
       "         74,  94],\n",
       "       [ 86, 110, 140, 107, 103, 120, 142, 131, 122, 116, 110, 105, 102,\n",
       "        102, 101, 100, 101,  98,  98,  96,  96,  97, 107,  95, 107,  80,\n",
       "         74, 102],\n",
       "       [124, 131, 145, 112, 114, 116, 119, 123, 127, 132, 135, 137, 139,\n",
       "        141, 144, 150, 150, 137, 127, 115, 107, 103, 103,  89,  89,  72,\n",
       "         72,  87],\n",
       "       [161, 165, 157, 155, 125, 127, 122, 123, 130, 140, 146, 148, 141,\n",
       "        135, 137, 145, 151, 139, 120, 100,  88,  84,  83,  80,  73,  70,\n",
       "         71,  75],\n",
       "       [181, 182, 175, 156, 117, 109,  98, 102, 107, 113, 109, 103,  97,\n",
       "         98,  98,  98, 105, 107, 106, 113, 104,  90,  84,  78,  73,  73,\n",
       "         71,  75],\n",
       "       [180, 177, 167, 158, 111,  95,  95, 105, 103, 104, 113, 121, 156,\n",
       "        173, 170, 153, 124, 110,  99, 111, 113,  95,  81,  77,  77,  74,\n",
       "         71,  74],\n",
       "       [143, 147, 119, 152, 110,  95, 101, 106, 105, 115, 148, 192, 228,\n",
       "        239, 236, 219, 191, 161, 124, 101, 100,  97,  84,  81,  82,  76,\n",
       "         75,  83],\n",
       "       [161, 113,  93, 138, 113,  99, 114, 113, 113, 136, 166, 185, 199,\n",
       "        224, 213, 187, 155, 144, 146, 117, 100, 105,  91,  91,  89,  79,\n",
       "         81,  86],\n",
       "       [193, 114,  78, 132, 117, 108, 120, 102, 126, 166, 153, 136, 143,\n",
       "        184, 188, 156, 136, 124, 157, 133,  97, 116, 105, 108,  97,  82,\n",
       "         82,  90],\n",
       "       [171, 125,  87, 130, 132, 118, 121,  97, 156, 204, 181, 170, 145,\n",
       "        127, 122, 150, 197, 152, 171, 161, 101, 103, 115, 104,  93,  84,\n",
       "         83,  96],\n",
       "       [145, 124,  99, 129, 149, 129, 123, 101, 175, 228, 221, 203, 167,\n",
       "        162, 152, 162, 212, 159, 166, 181, 109, 104, 118,  99,  90,  87,\n",
       "         85,  90],\n",
       "       [126, 124, 112, 124, 129, 137, 127, 103, 185, 234, 218, 180, 147,\n",
       "        173, 156, 148, 203, 160, 161, 170, 105, 105, 119,  94,  89,  87,\n",
       "         86,  93],\n",
       "       [116, 112, 107, 110, 116, 144, 129, 101, 159, 219, 188, 134, 140,\n",
       "        184, 169, 144, 162, 142, 168, 167, 103, 106, 115,  91,  88,  87,\n",
       "         91,  94],\n",
       "       [150, 150, 150, 149, 144, 146, 125, 105, 135, 179, 138, 115, 139,\n",
       "        166, 167, 153, 146, 161, 183, 142,  96, 105, 109,  93,  89,  90,\n",
       "         92,  94],\n",
       "       [180, 177, 175, 171, 159, 132, 132, 118, 107, 139, 170, 161, 160,\n",
       "        175, 193, 204, 211, 212, 168, 116, 104, 118, 100,  92,  92,  87,\n",
       "         88,  89],\n",
       "       [182, 176, 171, 169, 156, 118, 113, 127, 114, 108, 150, 198, 221,\n",
       "        232, 235, 235, 228, 188, 134, 118, 113, 100,  87,  91,  93,  86,\n",
       "         83,  84],\n",
       "       [157, 149, 140, 132, 154, 117,  97, 103, 119, 115, 110, 140, 169,\n",
       "        189, 194, 195, 197, 166, 128, 111, 100,  88,  82,  92,  85,  82,\n",
       "         78,  81],\n",
       "       [170, 129,  90, 104, 146, 119,  94,  90, 117, 131, 121, 105, 107,\n",
       "        116, 116, 118, 141, 151, 132, 114,  96,  81,  80,  91,  81,  81,\n",
       "         76,  80],\n",
       "       [194, 156,  81,  94, 142, 122,  99,  94, 108, 119, 124, 117, 117,\n",
       "        118, 113, 117, 125, 135, 132, 116,  95,  79,  79,  88,  79,  80,\n",
       "         78,  82],\n",
       "       [149, 135,  98,  91, 144, 132, 109, 109, 110, 115, 122, 129, 135,\n",
       "        137, 132, 129, 132, 141, 131, 113,  96,  80,  76,  81,  80,  80,\n",
       "         81,  82],\n",
       "       [132, 122, 108, 106, 139, 151, 138, 136, 134, 133, 132, 131, 131,\n",
       "        134, 133, 120, 115, 119, 118, 111, 104,  87,  73,  75,  79,  78,\n",
       "         78,  88],\n",
       "       [133, 125, 117, 115, 119, 119, 114, 111, 109, 109, 108, 100,  97,\n",
       "        126, 138, 113, 104, 122, 134, 118, 104,  93,  76,  73,  81,  89,\n",
       "         93,  99],\n",
       "       [ 98,  98,  85,  76,  79,  83,  88,  91,  93,  93,  85,  79,  81,\n",
       "        111, 138, 113, 103, 129, 155, 127, 103,  91,  79,  73,  88,  99,\n",
       "        108, 101],\n",
       "       [ 85,  98,  71,  69,  70,  82,  92,  87,  85,  93,  92,  81,  80,\n",
       "        108, 137, 113, 100, 128, 151, 124,  99,  96,  86,  73,  79,  99,\n",
       "        100,  94]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R2Z_mvJSD7j7"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "tensor_x_treino = torch.from_numpy(np.array(X, dtype=np.uint8)).to(torch.float32)\n",
    "tensor_x_teste = torch.from_numpy(np.array(Xt, dtype=np.uint8)).to(torch.float32)\n",
    "\n",
    "tensor_y_treino = torch.from_numpy(np.array(y, dtype=np.uint8)).to(torch.long)\n",
    "tensor_y_teste = torch.from_numpy(np.array(yt, dtype=np.uint8)).to(torch.long)\n",
    "\n",
    "dataset_treino = TensorDataset(tensor_x_treino,tensor_y_treino)\n",
    "dataset_teste = TensorDataset(tensor_x_teste,tensor_y_teste)\n",
    "\n",
    "trainloader = DataLoader(dataset_treino)\n",
    "testloader = DataLoader(dataset_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1756329164861,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "DobIfrBiWvq1",
    "outputId": "0081ca80-9cbd-4a05-e72e-1e37988503f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Visualizando uma imagem percorrendo o dataloader\n",
    "# (1, 1, 28, 28)\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "#imshow(image[0])\n",
    "print(image[0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibJKWEXGJoTE"
   },
   "source": [
    "Label\t| Description\n",
    "\n",
    "0\t    | T-shirt/top | Camiseta/Blusa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8bis7RYrXTOl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXl0ahiBX3US"
   },
   "source": [
    "### Criando uma rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vle1LawTX5T6"
   },
   "outputs": [],
   "source": [
    "# Criação da classe queno formato especificado pelo pytorch\n",
    "# Classifier é o nome escolhido para a o objeto\n",
    "# dados de entrada (28x28 = 784)\n",
    "# RNA totalmente conectada\n",
    "# saída: 10 classes (camisas, sapatos, etc.)\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Camadas lineares para as conexões\n",
    "        self.fc1 = nn.Linear(784, 256) # camada intermediaria 1\n",
    "        self.fc2 = nn.Linear(256, 128) # camada intermediaria 2\n",
    "        self.fc3 = nn.Linear(128, 64)  # camada intermediaria 3\n",
    "        self.fc4 = nn.Linear(64, 43)   # camada de saida\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x)) # Aplciação da função relu apos o somatório linear\n",
    "        x = F.relu(self.fc2(x)) # Aplciação da função relu apos o somatório linear\n",
    "        x = F.relu(self.fc3(x)) # Aplciação da função relu apos o somatório linear\n",
    "\n",
    "        x = self.fc4(x)         # Não é necessário aplicação da função de ativação na última camada, pois iremos calcular as probabilidades com esta saída\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756328414885,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "unSPs1FeZFiU",
    "outputId": "75c068a0-3288-4d06-fbca-08f35e794e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=43, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Criando objeto da estrutura da rede\n",
    "\n",
    "net = Classifier()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1756328414898,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "u8z1wcGyVsv6",
    "outputId": "17fb8d0c-ca02-4e7f-f591-d17416c54e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0073, -0.0343,  0.0130,  ...,  0.0060,  0.0311, -0.0161],\n",
      "        [-0.0329,  0.0171,  0.0017,  ..., -0.0107,  0.0346,  0.0076],\n",
      "        [ 0.0346, -0.0338, -0.0145,  ..., -0.0316, -0.0284,  0.0318],\n",
      "        ...,\n",
      "        [ 0.0260,  0.0301, -0.0061,  ..., -0.0171, -0.0216,  0.0182],\n",
      "        [-0.0092,  0.0024, -0.0264,  ...,  0.0321, -0.0027,  0.0045],\n",
      "        [ 0.0061, -0.0123,  0.0063,  ...,  0.0026,  0.0080, -0.0293]],\n",
      "       requires_grad=True)\n",
      " \n",
      "torch.Size([256, 784])\n"
     ]
    }
   ],
   "source": [
    "# Onde estão os pesos da rede?\n",
    "# Os pesos estão entre [-1, 1]\n",
    "\n",
    "print(net.fc1.weight)\n",
    "print(' ')\n",
    "print(net.fc1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qlyyytrUZHBB"
   },
   "outputs": [],
   "source": [
    "# Definindo parâmetros importantes do treinamento\n",
    "#Função de custo e função de otimização dos parâmetros\n",
    "# Faz-se necessário passar os parâmetros da rede e a taxa de aprendizado (learning rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4PlwUfHZas0"
   },
   "source": [
    "### Etapa de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1756328415351,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "LBtXGdpIZcIj",
    "outputId": "8fdabb45-c582-4e65-ef15-aa07cbe980ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando disponibilidade da gpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available else torch.devide('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diaehJiVZl02"
   },
   "source": [
    "## Adiciona a rede para a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1756328415355,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "uKWd6FNdZdbF",
    "outputId": "f31812ed-ae02-460b-d2c0-31eff7048155"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "u-ISlKK4ZfNn"
   },
   "outputs": [],
   "source": [
    "# Função que define o fluxo de treinamento\n",
    "\n",
    "def training_loop(loader, epoch):\n",
    "    running_loss = 0.\n",
    "    running_accuracy = 0.\n",
    "\n",
    "    # loop interno para pegar os batches de imagens\n",
    "    for i, data in enumerate(loader):\n",
    "\n",
    "        # pega os dados de entrada e saida\n",
    "        inputs, labels = data\n",
    "\n",
    "        # inseri os dados na gpu\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zera o gradiente\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Passa as imagens na rede e o resultado é armazenado em outputs\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Calcula o erro do batch\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Realiza o backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualiza os pesos\n",
    "        optimizer.step()\n",
    "\n",
    "        # Agrupa o erro do batch\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calcula a probabilidade com a função softmax\n",
    "        ps = F.softmax(outputs)\n",
    "\n",
    "        # Identifica pelo indice a classe com maior probabilidade para comparar com os labels originais\n",
    "        top_p, top_class = ps.topk(k = 1, dim = 1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "        # equals se transforma em um vetor de zeros e ums, logo podemos calcular a acuarcia como abaixo\n",
    "        accuracy = torch.mean(equals.type(torch.float))\n",
    "\n",
    "        running_accuracy += accuracy\n",
    "\n",
    "\n",
    "        # Imprimindo os dados referentes a este batch\n",
    "        #print(f'\\rÉpoca {epoch+1:3d} - Batch {i+1:3d} de {len(loader):3d}: perda {loss:03.2f} - acurácia {accuracy:03.2f}')\n",
    "\n",
    "    # Imprimindo os dados referentes a esta época\n",
    "    print(f'\\rÉPOCA {epoch+1:3d} FINALIZADA: perda {running_loss/len(loader):.5f} - acurácia {running_accuracy/len(loader):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "error",
     "timestamp": 1756328415488,
     "user": {
      "displayName": "Igor Gonçalves",
      "userId": "16259977477645896055"
     },
     "user_tz": 180
    },
    "id": "Xl-rGXQdaUKz",
    "outputId": "77d64273-b2a0-4002-913c-29c3bb7f6f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\AppData\\Local\\Temp\\ipykernel_16684\\653912730.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  ps = F.softmax(outputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÉPOCA   1 FINALIZADA: perda nan - acurácia 0.15413\n",
      "Testando...\n",
      "ÉPOCA   1 FINALIZADA: perda nan - acurácia 0.00454\n",
      "Treinando...\n",
      "ÉPOCA   2 FINALIZADA: perda nan - acurácia 0.00556\n",
      "Testando...\n",
      "ÉPOCA   2 FINALIZADA: perda nan - acurácia 0.00454\n",
      "Treinando...\n",
      "ÉPOCA   3 FINALIZADA: perda nan - acurácia 0.00556\n",
      "Testando...\n",
      "ÉPOCA   3 FINALIZADA: perda nan - acurácia 0.00454\n",
      "Treinando...\n",
      "ÉPOCA   4 FINALIZADA: perda nan - acurácia 0.00556\n",
      "Testando...\n",
      "ÉPOCA   4 FINALIZADA: perda nan - acurácia 0.00454\n",
      "Treinando...\n",
      "ÉPOCA   5 FINALIZADA: perda nan - acurácia 0.00556\n",
      "Testando...\n",
      "ÉPOCA   5 FINALIZADA: perda nan - acurácia 0.00454\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "  print('Treinando...')\n",
    "  training_loop(trainloader, epoch)\n",
    "  net.eval()\n",
    "  print('Testando...')\n",
    "  training_loop(testloader, epoch)\n",
    "  net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2FkKw-sa4vq"
   },
   "source": [
    "### Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Pn7xQI7za6j5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x272a12d16f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Percorrendo as imagens do loader de teste e pegando uma imagem unica\n",
    "\n",
    "imagem = next(iter(testloader))[0][0].view(28,28)\n",
    "plt.imshow(imagem, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Hvww7YGrbCF0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yQjPSU7YbavX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatando imagem para o shape requerido pelo pytorch\n",
    "\n",
    "imagem = imagem.view(1, 1, 28, 28)\n",
    "imagem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AWDEaTBGbFGf"
   },
   "outputs": [],
   "source": [
    "# Colocando a rede no modo eval e passando para gpu\n",
    "\n",
    "net.eval()\n",
    "imagem = imagem.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NQFlAYJCbMZH"
   },
   "outputs": [],
   "source": [
    "# Realizando previsão\n",
    "\n",
    "previsao = net.forward(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GoJ3yuazbSvI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# verificando respostas\n",
    "# Estes valores são chamados de 'score'.\n",
    "\n",
    "print(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aCkwve0Abm_i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Aplicando softmax nos scores para gerar as probabilidades\n",
    "\n",
    "prob = F.softmax(previsao, dim=1)\n",
    "\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Dc9TSMmvbqIO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      "  nan nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "# Selecionando apenas os resultados\n",
    "\n",
    "prob = prob.cpu().detach().numpy()\n",
    "\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SNrGcLu3b2Up"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classe predita é: 0\n",
      "\n",
      " Classe: Speed limit (20km/h)\n"
     ]
    }
   ],
   "source": [
    "# verificando o resultado\n",
    "\n",
    "resultado = np.argmax(prob)\n",
    "\n",
    "print(f'A classe predita é: {resultado}')\n",
    "\n",
    "classes = {\n",
    "    0: \"Speed limit (20km/h)\",\n",
    "    1: \"Speed limit (30km/h)\",\n",
    "    2: \"Speed limit (50km/h)\",\n",
    "    3: \"Speed limit (60km/h)\",\n",
    "    4: \"Speed limit (70km/h)\",\n",
    "    5: \"Speed limit (80km/h)\",\n",
    "    6: \"End of speed limit (80km/h)\",\n",
    "    7: \"Speed limit (100km/h)\",\n",
    "    8: \"Speed limit (120km/h)\",\n",
    "    9: \"No passing\",\n",
    "    10: \"No passing for vehicles over 3.5 metric tons\",\n",
    "    11: \"Right-of-way at the next intersection\",\n",
    "    12: \"Priority road\",\n",
    "    13: \"Yield\",\n",
    "    14: \"Stop\",\n",
    "    15: \"No vehicles\",\n",
    "    16: \"Vehicles over 3.5 metric tons prohibited\",\n",
    "    17: \"No entry\",\n",
    "    18: \"General caution\",\n",
    "    19: \"Dangerous curve to the left\",\n",
    "    20: \"Dangerous curve to the right\",\n",
    "    21: \"Double curve\",\n",
    "    22: \"Bumpy road\",\n",
    "    23: \"Slippery road\",\n",
    "    24: \"Road narrows on the right\",\n",
    "    25: \"Road work\",\n",
    "    26: \"Traffic signals\",\n",
    "    27: \"Pedestrians\",\n",
    "    28: \"Children crossing\",\n",
    "    29: \"Bicycles crossing\",\n",
    "    30: \"Beware of ice/snow\",\n",
    "    31: \"Wild animals crossing\",\n",
    "    32: \"End of all speed and passing limits\",\n",
    "    33: \"Turn right ahead\",\n",
    "    34: \"Turn left ahead\",\n",
    "    35: \"Ahead only\",\n",
    "    36: \"Go straight or right\",\n",
    "    37: \"Go straight or left\",\n",
    "    38: \"Keep right\",\n",
    "    39: \"Keep left\",\n",
    "    40: \"Roundabout mandatory\",\n",
    "    41: \"End of no passing\",\n",
    "    42: \"End of no passing by vehicles over 3.5 metric tons\"\n",
    "}\n",
    "\n",
    "\n",
    "print('\\n Classe: ' + classes[resultado])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 | Speed limit (20km/h)\n",
    "\n",
    "1 | Speed limit (30km/h)\n",
    "\n",
    "2 | Speed limit (50km/h)\n",
    "\n",
    "3 | Speed limit (60km/h)\n",
    "\n",
    "4 | Speed limit (70km/h)\n",
    "\n",
    "5 | Speed limit (80km/h)\n",
    "\n",
    "6 | End of speed limit (80km/h)\n",
    "\n",
    "7 | Speed limit (100km/h)\n",
    "\n",
    "8 | Speed limit (120km/h)\n",
    "\n",
    "9 | No passing\n",
    "\n",
    "10 | No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "11 | Right-of-way at the next intersection\n",
    "\n",
    "12 | Priority road\n",
    "\n",
    "13 | Yield\n",
    "\n",
    "14 | Stop\n",
    "\n",
    "15 | No vehicles\n",
    "\n",
    "16 | Vehicles over 3.5 metric tons prohibited\n",
    "\n",
    "17 | No entry\n",
    "\n",
    "18 | General caution\n",
    "\n",
    "19 | Dangerous curve to the left\n",
    "\n",
    "20 | Dangerous curve to the right\n",
    "\n",
    "21 | Double curve\n",
    "\n",
    "22 | Bumpy road\n",
    "\n",
    "23 | Slippery road\n",
    "\n",
    "24 | Road narrows on the right\n",
    "\n",
    "25 | Road work\n",
    "\n",
    "26 | Traffic signals\n",
    "\n",
    "27 | Pedestrians\n",
    "\n",
    "28 | Children crossing\n",
    "\n",
    "29 | Bicycles crossing\n",
    "\n",
    "30 | Beware of ice/snow\n",
    "\n",
    "31 | Wild animals crossing\n",
    "\n",
    "32 | End of all speed and passing limits\n",
    "\n",
    "33 | Turn right ahead\n",
    "\n",
    "34 | Turn left ahead\n",
    "\n",
    "35 | Ahead only\n",
    "\n",
    "36 | Go straight or right\n",
    "\n",
    "37 | Go straight or left\n",
    "\n",
    "38 | Keep right\n",
    "\n",
    "39 | Keep left\n",
    "\n",
    "40 | Roundabout mandatory\n",
    "\n",
    "41 | End of no passing\n",
    "\n",
    "42 | End of no passing by vehicles over 3.5 metric ton"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "dali",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
